# NexQA.ai Docker Environment Configuration
# Copy this file to .env for Docker Compose
# Example: cp .env.docker .env

# ==================== EMBEDDING PROVIDER ====================
# Choose: 'ollama' (local, free) or 'azure' (cloud, paid)
EMBEDDING_PROVIDER=ollama

# ==================== OLLAMA CONFIGURATION ====================
# Docker container name for Ollama
OLLAMA_HOST=http://ollama:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest

# ==================== CHROMADB CONFIGURATION ====================
# Auto-set to /data/chroma_db in Docker (do not change)
CHROMA_DB_PATH=/data/chroma_db

# ==================== AZURE OPENAI CONFIGURATION ====================
# Only fill these if EMBEDDING_PROVIDER=azure

# Your Azure OpenAI API Key
AZURE_OPENAI_API_KEY=

# Your Azure OpenAI Endpoint (e.g., https://your-resource.openai.azure.com/)
AZURE_OPENAI_ENDPOINT=

# API Version (optional)
AZURE_OPENAI_API_VERSION=2024-02-01

# Embedding Model Deployment Name
AZURE_EMBEDDING_MODEL=text-embedding-ada-002

# Chat Model Deployment Name
AZURE_OPENAI_MODEL=gpt-4

# ==================== NOTES ====================
# Docker Ports:
# - Frontend: 3000
# - Backend: 5000
# - Ollama: 11434
#
# Data Volumes (persisted across restarts):
# - ChromaDB: nexqa-chroma (persists vector database)
# - Ollama: nexqa-ollama (persists downloaded models)
# - Uploads: backend/uploads (persists uploaded files)
